[ {
    "id" : "funeval:iclr18",
    "title" : "Combining Symbolic Expressions and Black-box Function Evaluations for Training Neural Programs",
    "pubTypeSlot" : "Conference",
    "year" : 2018,
    "authorIds" : [ "Forough Arabshahi", "sameer", "Animashree Anandkumar" ],
    "extraLinksSlot" : [ [ "ArXiv Page", "https://arxiv.org/abs/1801.04342" ], [ "OpenReview Page", "https://openreview.net/forum?id=Hksj2WWAW" ] ],
    "pdfLink" : "https://arxiv.org/pdf/1801.04342",
    "venueId" : "iclr"
}, {
    "id" : "natadv:iclr18",
    "title" : "Generating Natural Adversarial Examples",
    "pubTypeSlot" : "Conference",
    "year" : 2018,
    "authorIds" : [ "zhengli", "dheeru", "sameer" ],
    "extraLinksSlot" : [ [ "ArXiv Page", "https://arxiv.org/abs/1710.11342" ], [ "OpenReview Page", "https://openreview.net/forum?id=H1BLjgZCb" ] ],
    "pdfLink" : "https://arxiv.org/pdf/1710.11342",
    "venueId" : "iclr",
    "weight" : 1.5
}, {
    "id" : "anchors:aaai18",
    "title" : "Anchors: High-Precision Model-Agnostic Explanations",
    "pubTypeSlot" : "Conference",
    "year" : 2018,
    "authorIds" : [ "marco", "sameer", "carlos" ],
    "pdfLink" : "files/papers/anchors-aaai18.pdf",
    "venueId" : "aaai"
},{
    "id" : "mmkbe:akbc17",
    "title" : "Embedding Multimodal Relational Data",
    "pubTypeSlot" : "Workshop",
    "year" : 2017,
    "pdfLink" : "http://www.akbc.ws/2017/papers/26_paper.pdf",
    "authorIds" : [ "Pouya Pezeshkpour", "Liyan Chen", "sameer" ],
    "venueId" : "akbc"
},{
    "id" : "maed:akbc17",
    "title" : "Multimodal Attribute Extraction",
    "pubTypeSlot" : "Workshop",
    "year" : 2017,
    "authorIds" : [ "Robert L. Logan", "Samuel Humeau", "sameer" ],
    "pdfLink" : "http://www.akbc.ws/2017/papers/19_paper.pdf",
    "venueId" : "akbc"
}, {
    "id" : "semcompress:asilomar17",
    "title" : "Intelligent Data Filtering in Constrained IoT Systems",
    "pubTypeSlot" : "Invited",
    "year" : 2017,
    "authorIds" : [ "Igor Burago", "Davide Callegaro", "levorato", "sameer" ],
    "venueId" : "Asilomar Conference on Signals, Systems, and Computers",
    "abstractText" : "The expansion of complex autonomous sensing and control mechanisms in the Internet-of-Things systems clashes with constraints on computation and wireless communication resources. In this paper, we propose a framework to address this conflict for applications in which resolution using a centralized architecture with a general-purpose compression of observations is not appropriate. Three approaches for distributing observation detection workload between sensing and processing devices are considered for sensor systems within wireless islands. Each of the approaches is formulated for the shared configuration of a sensor-edge system, in which the network structure, observation monitoring problem, and machine learning-based detector implementing it are not modified. For every approach, a high-level strategy for realization of the detector for different assumptions on the relation between its complexity and the system's constraints is considered. In each case, the potential for the constraints' satisfaction is shown to exist and be exploitable via division, approximation, and delegation of the detector's workload to the sensing devices off the edge processor. We present examples of applications that benefit from the proposed approaches."
}, {
    "id" : "natadv:mldecept17",
    "title" : "Generating Natural Adversarial Examples",
    "pubTypeSlot" : "Workshop",
    "year" : 2017,
    "authorIds" : [ "zhengli", "dheeru", "sameer" ],
    "extraLinksSlot" : [ [ "ArXiv Page", "https://arxiv.org/abs/1710.11342" ] ],
    "pdfLink" : "https://arxiv.org/pdf/1710.11342",
    "venueId" : "NIPS Workshop on Machine Deception",
    "abstractText" : "Due to their complex nature, it is hard to characterize the ways in which machine learning models can misbehave or be exploited when deployed. Recent work on adversarial examples, i.e. inputs with minor perturbations that result in substantially different model predictions, is helpful in evaluating the robustness of these models by exposing the adversarial scenarios where they fail. However, these malicious perturbations are often unnatural, not semantically meaningful, and not applicable to complicated domains such as language. In this paper, we propose a framework to generate natural and legible adversarial examples by searching in semantic space of dense and continuous data representation, utilizing the recent advances in generative adversarial networks. We present generated adversaries to demonstrate the potential of the proposed approach for black-box classifiers in a wide range of applications such as image classification, textual entailment, and machine translation. We include experiments to show that the generated adversaries are natural, legible to humans, and useful in evaluating and analyzing black-box classifiers.",
    "emphasisNote" : "Amazon Best Poster Award at the Southern California Machine Learning Symposium.",
    "note" : "Shorter version of the paper at ICLR 2018.",
    "weight" : 1.5
}, {
    "id" : "tsunami:geosense18",
    "title" : "A Framework of Rapid Regional Tsunami Damage Recognition from Post-event TerraSAR-X Imagery Using Deep Neural Networks",
    "pubTypeSlot" : "Journal",
    "year" : 2017,
    "authorIds" : [ "Yanbing Bai", "Chang Gao", "sameer",  "Magaly Koch", "Bruno Adriano", "Erick Mas", "Shunichi Koshimura" ],
    "pdfLink" : "http://ieeexplore.ieee.org/document/8126255/",
    "venueId" : "IEEE Geoscience and Remote Sensing Letters",
    "extraFieldsSlot" : [["volume", "PP"]],
    "abstractText" : "Near real-time building damage mapping is an indispensable prerequisite for governments to make decisions for disaster relief. With high-resolution synthetic aperture radar (SAR) systems, such as TerraSAR-X, the provision of such products in a fast and effective way becomes possible. In this letter, a deep learning-based framework for rapid regional tsunami damage recognition using post-event SAR imagery is proposed. To perform such a rapid damage mapping, a series of tile-based image split analysis is employed to generate the data set. Next, a selection algorithm with the SqueezeNet network is developed to swiftly distinguish between built-up (BU) and nonbuilt-up regions. Finally, a recognition algorithm with a modified wide residual network is developed to classify the BU regions into wash away, collapsed, and slightly damaged regions. Experiments performed on the TerraSAR-X data from the 2011 Tohoku earthquake and tsunami in Japan show a BU region extraction accuracy of 80.4% and a damage-level recognition accuracy of 74.8%, respectively. Our framework takes around 2 h to train on a new region, and only several minutes for prediction."
}, {
    "id" : "neuralel:emnlp17",
    "title" : "Entity Linking via Joint Encoding of Types, Descriptions, and Context",
    "pubTypeSlot" : "Conference",
    "year" : 2017,
    "authorIds" : [ "nitish", "sameer", "roth" ],
    "extraLinksSlot" : [ [ "Project Page", "http://cogcomp.org/page/publication_view/817" ] ],
    "pdfLink" : "http://cogcomp.org/papers/GuptaSiRo17.pdf",
    "venueId" : "emnlp",
    "extraFieldsSlot" : [ ["month", "September"] ],
    "abstractText" : "For accurate entity linking, we need to capture various information aspects of an entity, such as its description in a KB, contexts in which it is mentioned, and structured knowledge. Additionally, a linking system should work on texts from different domains without requiring domain-specific training data or hand-engineered features.<br>In this work we present a neural, modular entity linking system that learns a unified dense representation for each entity using multiple sources of information, such as its description, contexts around its mentions, and its fine-grained types. We show that the resulting entity linking system is effective at combining these sources, and performs competitively, sometimes out-performing current state-of-the-art systems across datasets, without requiring any domain-specific training data or hand-engineered features. We also show that our model can effectively \"embed\" entities that are new to the KB, and is able to link its mentions accurately."
}, {
    "id" : "saul:starai17",
    "title" : "Relational Learning and Feature Extraction by Querying over Heterogeneous Information Networks",
    "pubTypeSlot" : "Workshop",
    "year" : 2017,
    "authorIds" : [ "parisa", "sameer", "Daniel Khashabi", "Christos Christodoulopoulos", "Mark Summons", "Saurabh Sinha", "roth" ],
    "extraLinksSlot" : [ [ "ArXiv version", "https://arxiv.org/pdf/1707.07794" ] ],
    "pdfLink" : "https://arxiv.org/pdf/1707.07794",
    "venueId" : "starai",
    "extraFieldsSlot" : [ ["month", "July"] ],
    "abstractText" : "Many real world systems need to operate on heterogeneous information networks that consist of numerous interacting components of different types. Examples include systems that perform data analysis on biological information networks; social networks; and information extraction systems processing unstructured data to convert raw text to knowledge graphs. Many previous works describe specialized approaches to perform specific types of analysis, mining and learning on such networks. In this work, we propose a unified framework consisting of a data model -a graph with a first order schema along with a declarative language for constructing, querying and manipulating such networks in ways that facilitate relational and structured machine learning. In particular, we provide an initial prototype for a relational and graph traversal query language where queries are directly used as relational features for structured machine learning models. Feature extraction is performed by making declarative graph traversal queries. Learning and inference models can directly operate on this relational representation and augment it with new data and knowledge that, in turn, is integrated seamlessly into the relational structure to support new predictions. We demonstrate this system's capabilities by showcasing tasks in natural language processing and computational biology domains."
}, {
    "id" : "gender:winlp17",
    "title" : "How Biased Are We? Automated Detection of Gendered Language",
    "pubTypeSlot" : "Workshop",
    "year" : 2017,
    "authorIds" : [ "ananya", "sameer" ],
    "extraFieldsSlot" : [ ["month", "August"] ],
    "pdfLink" : "http://www.winlp.org/wp-content/uploads/2017/final_papers_2017/80_Paper.pdf",
    "venueId" : "ACL Workshop on Women and Underrepresented Minorities in NLP (WiNLP)",
    "note" : "Also presented at the NIPS 2017 Workshop for Women in Machine Learning (WiML).",
    "weight" : 0.5
}, {
    "id" : "semcompress:ita17",
    "title" : "Semantic Compression for Edge-Assisted Systems",
    "pubTypeSlot" : "Invited",
    "year" : 2017,
    "extraLinksSlot" : [ [ "ArXiv version", "https://arxiv.org/abs/1702.05863" ] ],
    "pdfLink" : "https://arxiv.org/pdf/1702.05863",
    "extraFieldsSlot" : [ ["month", "February"] ],
    "authorIds" : [ "Igor Burago", "levorato", "sameer" ],
    "venueId" : "Information Theory and Applications (ITA) Workshop"
}, {
    "id" : "saul:coling16",
    "title" : "Better call Saul: Flexible Programming for Learning and Inference in NLP",
    "pubTypeSlot" : "Conference",
    "year" : 2016,
    "extraFieldsSlot" : [ ["month", "December"] ],
    "authorIds" : [ "parisa", "Daniel Khashabi", "Christos Christodoulopoulos", "Bhargav Mangipudi", "sameer", "roth" ],
    "venueId" : "coling",
    "pdfLink" : "http://aclanthology.coli.uni-saarland.de/pdf/C/C16/C16-1285.pdf"
}, {
    "id" : "connot:acl16",
    "title" : "Connotation Frames: A Data-Driven Investigation",
    "pubTypeSlot" : "Conference",
    "year" : 2016,
    "extraFieldsSlot" : [ ["month", "August"] ],
    "authorIds" : [ "rashkin", "sameer", "yejin" ],
    "extraLinksSlot" : [ [ "ArXiv version", "http://arxiv.org/abs/1506.02739" ], [ "Project page", "http://homes.cs.washington.edu/~hrashkin/connframe.html" ] ],
    "pdfLink" : "files/papers/connot-acl16.pdf",
    "venueId" : "acl"
}, {
    "id" : "prog:nipsws16",
    "title" : "Programs as Black-Box Explanations",
    "pubTypeSlot" : "Workshop",
    "year" : 2016,
    "authorIds" : [ "sameer", "marco", "carlos" ],
    "extraLinksSlot" : [ [ "ArXiv version", "https://arxiv.org/abs/1611.07579" ] ],
    "venueId" : "interpretML",
    "extraFieldsSlot" : [ ["month", "November"] ],
    "abstractText" : "Recent work in model-agnostic explanations of black-box machine learning has demonstrated that interpretability of complex models does not have to come at the cost of accuracy or model flexibility. However, it is not clear what kind of explanations, such as linear models, decision trees, and rule lists, are the appropriate family to consider, and different tasks and models may benefit from different kinds of explanations. Instead of picking a single family of representations, in this work we propose to use \"programs\" as model-agnostic explanations. We show that small programs can be expressive yet intuitive as explanations, and generalize over a number of existing interpretable families. We propose a prototype program induction method based on simulated annealing that approximates the local behavior of black-box classifiers around a specific prediction using random perturbations. Finally, we present preliminary application on small datasets and show that the generated explanations are intuitive and accurate for a number of classifiers."
}, {
    "id" : "anchor:nipsws16",
    "title" : "Nothing Else Matters: Model-Agnostic Explanations By Identifying Prediction Invariance",
    "pubTypeSlot" : "Workshop",
    "year" : 2016,
    "authorIds" : [ "marco", "sameer", "carlos" ],
    "extraLinksSlot" : [ [ "ArXiv version", "https://arxiv.org/abs/1611.05817" ] ],
    "venueId" : "interpretML",
    "extraFieldsSlot" : [ ["month", "November"] ],
    "abstractText" : "At the core of interpretable machine learning is the question of whether humans are able to make accurate predictions about a model's behavior. Assumed in this question are three properties of the interpretable output: coverage, precision, and effort. Coverage refers to how often humans think they can predict the model's behavior, precision to how accurate humans are in those predictions, and effort is either the up-front effort required in interpreting the model, or the effort required to make predictions about a model's behavior.<br>In this work, we propose anchor-LIME (aLIME), a model-agnostic technique that produces high-precision rule-based explanations for which the coverage boundaries are very clear. We compare aLIME to linear LIME with simulated experiments, and demonstrate the flexibility of aLIME with qualitative examples from a variety of domains and tasks."
}, {
    "id" : "lime:oreilly16",
    "title" : "Introduction to Local Interpretable Model-Agnostic Explanations (LIME)",
    "pubTypeSlot" : "Online",
    "year" : 2016,
    "authorIds" : [ "marco", "sameer", "carlos" ],
    "venueId" : "O'Reilly Media",
    "extraFieldsSlot" : [ ["month", "August"] ],
    "extraFieldsSlot" : [ ["url", "https://www.oreilly.com/learning/introduction-to-local-interpretable-model-agnostic-explanations-lime"] ],
    "extraLinksSlot" : [ [ "Article", "https://www.oreilly.com/learning/introduction-to-local-interpretable-model-agnostic-explanations-lime" ] ]
}, {
    "id" : "lime:hcml16",
    "title" : "\"Why Should I Trust You?\": Explaining the Predictions of Any Classifier",
    "pubTypeSlot" : "Workshop",
    "year" : 2016,
    "authorIds" : [ "marco", "sameer", "carlos" ],
    "venueId" : "CHI Workshop on Human-Centred Machine Learning (HCML)",
    "extraFieldsSlot" : [ ["month", "May"] ],
    "pdfLink" : "files/papers/lime-hcml16.pdf",
    "note" : "Shorter version of the paper presented at KDD 2016."
}, {
    "id" : "lime:whi16",
    "title" : "Model-Agnostic Interpretability of Machine Learning",
    "pubTypeSlot" : "Workshop",
    "year" : 2016,
    "authorIds" : [ "marco", "sameer", "carlos" ],
    "extraFieldsSlot" : [ ["month", "June"] ],
    "pdfLink" : "files/papers/lime-whi16.pdf",
    "emphasisNote" : "Best Paper Award",
    "venueId" : "ICML Workshop on Human Interpretability in Machine Learning (WHI)"
}, {
    "id" : "lime:kdd16",
    "title" : "\"Why Should I Trust You?\": Explaining the Predictions of Any Classifier",
    "pubTypeSlot" : "Conference",
    "year" : 2016,
    "authorIds" : [ "marco", "sameer", "carlos" ],
    "venueId" : "kdd",
    "extraLinksSlot" : [ [ "ArXiv version", "http://arxiv.org/abs/1602.04938" ], [ "Project page", "https://github.com/marcotcr/lime"], [ "Summary Video", "https://www.youtube.com/watch?v=hUnRCxnydCc"], [ "Article on O'Reilly", "https://oreilly.com/learning/introduction-to-local-interpretable-model-agnostic-explanations-lime"], [ "Code for Synthetic Experiments", "https://github.com/marcotcr/lime-experiments"] ],
    "extraFieldsSlot" : [ ["month", "August"] ],
    "pdfLink" : "files/papers/lime-kdd16.pdf",
    "emphasisNote" : "Audience Appreciation Award",
    "note" : "Also presented at the CHI 2016 Workshop on Human-Centred Machine Learning (HCML)."
}, {
    "id" : "lime:naacl16",
    "title" : "\"Why Should I Trust You?\": Explaining the Predictions of Any Classifier",
    "pubTypeSlot" : "Demo",
    "year" : 2016,
    "authorIds" : [ "marco", "sameer", "carlos" ],
    "venueId" : "Demo at the Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL)",
    "extraFieldsSlot" : [ ["month", "June"] ],
    "pdfLink" : "files/papers/lime-naacl16demo.pdf",
    "extraLinksSlot" : [ [ "Source code", "https://github.com/UW-MODE/naacl16-demo" ] ],
    "note" : "Demonstration of the KDD 2016 paper."
}, {
    "id" : "moro:eaai16",
    "title" : "Creating Interactive and Visual Educational Resources for {AI}",
    "pubTypeSlot" : "Workshop",
    "year" : 2016,
    "authorIds" : [ "sameer", "sebastian" ],
    "venueId" : "AAAI Symposium on Educational Advances in Artificial Intelligence (EAAI)",
    "pdfLink" : "files/papers/moro-eaai16.pdf",
    "abstractText" : "Teaching artificial intelligence is effective if the experience is a visual and interactive one, with educational materials that utilize combinations of various content types such as text, math, and code into an integrated experience. Unfortunately, easy-to-use tools for creating such pedagogical resources are not available to the educators, resulting in most courses being taught using a disconnected set of static materials, which is not only ineffective for learning AI, but further, requires repeated and redundant effort for the instructor. In this paper, we introduce Moro, a software tool for easily creating and presenting AI-friendly teaching materials. Moro notebooks integrate content of different types (text, math, code, images), allow real-time interactions via modifiable and executable code blocks, and are viewable in browsers both as long-form pages and as presentations. Creating notebooks is easy and intuitive; the creation tool is also in-browser, is WYSIWYG for quick iterations of editing, and supports a variety of shortcuts and customizations for efficiency. We present three deployed case studies of Moro that widely differ from each other, demonstrating its utility in a variety of scenarios such as in-class teaching and conference tutorials."
}, {
    "id" : "logicmf:naacl15",
    "title" : "Injecting Logical Background Knowledge into Embeddings for Relation Extraction",
    "pubTypeSlot" : "Conference",
    "year" : 2015,
    "authorIds" : [ "tim", "sameer", "sebastian" ],
    "venueId" : "naacl",
    "pdfLink" : "files/papers/logicmf-naacl15.pdf",
    "pptLink" : "http://rockt.github.io/slides/2015-naacl.pdf",
    "extraLinksSlot" : [ [ "Source code", "https://github.com/uclmr/low-rank-logic" ], [ "Talk video", "http://techtalks.tv/talks/injecting-logical-background-knowledge-into-embeddings-for-relation-extraction/61526/" ] ],
    "abstractText" : "Matrix factorization approaches to relation extraction provide several attractive features: they support distant supervision, handle open schemas, and leverage unlabeled data. Unfortunately, these methods share a shortcoming with all other distantly supervised approaches: they cannot learn to extract target relations without existing data in the knowledge base, and likewise, these models are inaccurate for relations with sparse data. Rule-based extractors, on the other hand, can be easily extended to novel relations and improved for existing but inaccurate relations, through first-order formulae that capture auxiliary domain knowledge. However, usually a large set of such formulae is necessary to achieve generalization.<br>In this paper, we introduce a paradigm for learning low-dimensional embeddings of entity-pairs and relations that combine the advantages of matrix factorization with first-order logic domain knowledge. We introduce simple approaches for estimating such embeddings, as well as a novel training algorithm to jointly optimize over factual and first-order logic information. Our results show that this method is able to learn accurate extractors with little or no distant supervision alignments, while at the same time generalizing to textual patterns that do not appear in the formulae.",
    "weight" : 1.5
}, {
    "id" : "el:tacl15",
    "title" : "Design Challenges for Entity Linking",
    "pubTypeSlot" : "Journal",
    "year" : 2015,
    "authorIds" : [ "xiao", "sameer", "weld" ],
    "venueId" : "tacl",
    "pdfLink" : "files/papers/entitylinking-tacl15.pdf",
    "extraLinksSlot" : [ ["TACL Page", "https://tacl2013.cs.columbia.edu/ojs/index.php/tacl/article/view/528" ], [ "TACL PDF", "https://tacl2013.cs.columbia.edu/ojs/index.php/tacl/article/viewFile/528/133" ] ],
    "extraFieldsSlot" : [ ["volume", "3"] ],
    "note" : "To be presented at ACL, Beijing, July 26-31, 2015.",
    "abstractText" : "Recent research on entity linking (EL) has introduced a plethora of promising techniques, ranging from deep neural networks to joint inference. But despite numerous papers there is surprisingly little understanding of the state of the art in EL. We attack this confusion by analyzing differences between several versions of the EL problem and presenting a simple yet effective, modular, unsupervised system, called Vinculum, for entity linking. We conduct an extensive evaluation on nine data sets, comparing Vinculum with two state-of-the-art systems, and elucidate key aspects of the system that include mention extraction, candidate generation, entity type prediction, entity coreference, and coherence.",
    "weight" : 1.3
}, {
    "id" : "gbcrf:aistats15",
    "title" : "Efficient Second-Order Gradient Boosting for Conditional Random Fields",
    "pubTypeSlot" : "Conference",
    "year" : 2015,
    "authorIds" : [ "tianqi", "sameer", "taskar", "carlos" ],
    "venueId" : "aistats",
    "pdfLink" : "files/papers/gbcrf-aistats15.pdf",
    "weight" : 1.2
}, {
    "id" : "factordb:yelp15",
    "title" : "Collective Factorization for Relational Data: An Evaluation on the Yelp Datasets",
    "pubTypeSlot" : "TechReport",
    "year" : 2015,
    "authorIds" : [ "nitish", "sameer" ],
    "venueId" : "Yelp Dataset Challenge, Round 4",
    "pdfLink" : "files/papers/yelp-factordb.pdf",
    "extraLinksSlot" : [[ "Project Page", "http://nitishgupta.github.io/factorDB/" ], [ "Yelp Challenge", "http://www.yelp.com/dataset_challenge" ]],
    "emphasisNote" : "Grand Prize Winner of Yelp Dataset Challenge Round 4"
}, {
    "id" : "mftf:vsm15",
    "title" : "Towards Combined Matrix and Tensor Factorization for Universal Schema Relation Extraction",
    "pubTypeSlot" : "Workshop",
    "year" : 2015,
    "authorIds" : [ "sameer", "tim", "sebastian" ],
    "venueId" : "NAACL Workshop on Vector Space Modeling for NLP",
    "pdfLink" : "files/papers/mftf-vsm15.pdf"
}, {
    "id" : "wolfe:naacl15",
    "title" : "{WOLFE}: An {NLP}-friendly Declarative Machine Learning Stack",
    "pubTypeSlot" : "Demo",
    "year" : 2015,
    "authorIds" : [ "sameer", "tim", "Luke Hewitt", "Jason Naradowsky", "sebastian" ],
    "venueId" : "Demo at the Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL)",
    "pdfLink" : "files/papers/wolfe-naacl15-demo.pdf",
    "extraLinksSlot" : [ [ "Website", "http://www.wolfe.ml" ], [ "Live Demo", "http://wolfe.ml/demos/nlp" ] ],
    "abstractText" : "Developing machine learning algorithms for natural language processing (NLP) applications is inherently an iterative process, involving a continuous refinement of the choice of model, engineering of features, selection of inference algorithms, search for the right hyper-parameters, and error analysis. Existing probabilistic program languages (PPLs) only provide partial solutions; most of them do not support commonly used models such as matrix factorization or neural networks, and do not facilitate interactive and iterative programming that is crucial for rapid development of these models.<br>In this demo we introduce WOLFE, a stack designed to facilitate the development of NLP applications: (1) the WOLFE language allows the user to concisely define complex models, enabling easy modification and extension, (2) the WOLFE interpreter transforms declarative machine learning code into automatically differentiable terms or, where applicable, into factor graphs that allow for complex models to be applied to real-world applications, and (3) the WOLFE IDE provides a number of different visual and interactive elements, allowing intuitive exploration and editing of the data representations, the underlying graphical models, and the execution of the inference algorithms."
}, {
    "id" : "explain:krr15",
    "title" : "Towards Extracting Faithful and Descriptive Representations of Latent Variable Models",
    "pubTypeSlot" : "Workshop",
    "year" : 2015,
    "authorIds" : [ "Ivan Sanchez", "tim", "sebastian", "sameer" ],
    "venueId" : "krr",
    "pdfLink" : "files/papers/knowlextr-krr15.pdf",
    "extraLinksSlot" : [ [ "AAAI PDF", "http://www.aaai.org/ocs/index.php/SSS/SSS15/paper/viewFile/10304/10033" ] ],
    "weight" : 0.5
}, {
    "id" : "logicmf:krr15",
    "title" : "On Approximate Reasoning Capabilities of Low-Rank Vector Spaces",
    "pubTypeSlot" : "Workshop",
    "year" : 2015,
    "authorIds" : [ "guillaume", "sameer", "Theo Trouillon" ],
    "venueId" : "krr",
    "pdfLink" : "files/papers/logicmf-krr15.pdf",
    "extraLinksSlot" : [ [ "AAAI PDF", "http://www.aaai.org/ocs/index.php/SSS/SSS15/paper/viewFile/10257/10026" ] ],
    "weight" : 0.75
}, {
  "id" : "rdb:patent14",
  "title" : "Relational database management",
  "pubTypeSlot" : "Patent",
  "year" : 2014,
  "authorIds" : [ "sameer", "thore", "Lucas J. Bordeaux", "Andrew D. Gordon" ],
  "venueId" : "US Patent Number 0188928",
  "pdfLink" : "https://docs.google.com/viewer?url=patentimages.storage.googleapis.com/pdfs/US20140188928.pdf",
  "extraLinksSlot" : [ [ "Webpage", "https://www.google.com/patents/US20140188928" ] ],
  "weight" : 0.0
}, {
    "id" : "uw:kba14",
    "title" : "Distributed Non-Parametric Representations for Vital Filtering: {UW at TREC KBA} 2014",
    "pubTypeSlot" : "Conference",
    "year" : 2014,
    "authorIds" : [ "nacho", "sameer", "carlos" ],
    "venueId" : "Text REtrieval Conference (TREC): Knowledge-Base Acceleration (KBA) Track",
    "pdfLink" : "files/papers/stream-kba14.pdf",
    "weight" : 0.75
}, {
    "id" : "context:nwnlp14",
    "title" : "Context Representation for Named Entity Linking",
    "pubTypeSlot" : "Workshop",
    "year" : 2014,
    "authorIds" : [ "xiao", "sameer", "weld" ],
    "venueId" : "nwnlp",
    "pdfLink" : "files/papers/contextel-nwnlp14.pdf",
    "weight" : 0.5
}, {
    "id" : "prlr:mmlnlp14",
    "title" : "Multi-label Learning with Posterior Regularization",
    "pubTypeSlot" : "Workshop",
    "year" : 2014,
    "authorIds" : [ "victoria", "sameer", "luheng", "taskar", "lsz" ],
    "venueId" : "NIPS Workshop on Modern Machine Learning and Natural Language Processing",
    "note" : "Also presented at the Pacific Northwest Regional NLP Workshop (NW-NLP) 2014.",
    "pdfLink": "http://homes.cs.washington.edu/~xilin/pubs/mlnlp2014.pdf",
    "weight" : 0.5
}, {
    "id" : "kb-integration:akbc14",
    "title" : "Out of Many, One: Unifying Web-Extracted Knowledge Bases",
    "pubTypeSlot" : "Workshop",
    "year" : 2014,
    "authorIds" : [ "mathias", "sameer" ],
    "venueId" : "akbc",
    "pdfLink": "http://www.akbc.ws/2014/submissions/akbc2014_submission_28.pdf",
    "weight" : 0.75
}, {
    "id" : "ppl-ide:probprog14",
    "title" : "Designing an IDE for Probabilistic Programming: Challenges and a Prototype",
    "pubTypeSlot" : "Workshop",
    "year" : 2014,
    "authorIds" : [ "sameer", "sebastian", "Luke Hewitt", "tim" ],
    "venueId" : "probprog",
    "note" : "Also presented at NIPS 2014 as a demo.",
    "weight" : 0.75,
    "pdfLink" : "files/papers/pplide-nips14-ppl.pdf",
    "tagsSlot" : [ "Demo" ],
    "extraLinksSlot" : [ [ "Live Demo", "http://wolfe.ml/demos/nips" ], [ "Poster", "files/papers/pplide-nips14-ppl-poster.pdf" ] ]
}, {
    "id" : "logic:sp14",
    "title" : "Low-dimensional Embeddings of Logic",
    "pubTypeSlot" : "Workshop",
    "year" : 2014,
    "authorIds" : [ "tim", "sameer", "matko", "sebastian" ],
    "venueId" : "sp14",
    "pdfLink" : "files/papers/lowranklogic-sp14.pdf",
    "emphasisNote" : "Exceptional Submission Award",
    "note" : "Also presented at StarAI 2014 with minor changes.",
     "extraLinksSlot" : [ [ "StarAI Poster", "files/papers/lowranklogic-starai14-poster.pdf" ] ]
}, {
    "id" : "wolfe:starai14",
    "title" : "WOLFE: Strength Reduction and Approximate Programming for Probabilistic Programming",
    "pubTypeSlot" : "Workshop",
    "year" : 2014,
    "authorIds" : [ "sebastian", "sameer", "vivek", "tim", "larysa", "jan" ],
    "venueId" : "starai",
    "note" : "Also presented at NIPS Probabilistic Programming Workshop.",
    "pdfLink" : "files/papers/wolfe-starai14.pdf",
     "extraLinksSlot" : [ [ "Website", "http://www.wolfe.ml" ], [ "Poster", "files/papers/wolfe-starai14-poster.pdf" ] ]
}, {
    "id" : "thesis",
    "title" : "Scaling MCMC Inference and Belief Propagation for Large, Dense Graphical Models",
    "pubTypeSlot" : "Thesis",
    "year" : 2014,
    "authorIds" : [ "sameer" ],
    "venueId" : "University of Massachusetts",
    "pdfLink" : "https://web.cs.umass.edu/publication/docs/2014/UM-CS-PhD-2014-007.pdf",
    "note" : "Committee: Andrew McCallum, Carlos Guestrin, Ben Marlin, David Jensen, Michael Zink.",
    "abstractText" : "With the physical constraints of semiconductor-based electronics becoming increasingly limiting in the past decade, single-core CPUs have given way to multi-core and distributed computing platforms. At the same time, access to large data collections is progressively becoming commonplace due to the lowering cost of storage and bandwidth. Traditional machine learning paradigms that have been designed to operate sequentially on single processor architectures seem destined to become obsolete in this world of multi-core, multi-node systems and massive data sets. Inference for graphical models is one such example for which most existing algorithms are sequential in nature and are difficult to scale using parallel computations. Further, modeling large datasets leads to an escalation in the number of variables, factors, domains, and the density of the models, all of which have a substantial impact on the computational and storage complexity of inference. To achieve scalability, existing techniques impose strict independence assumptions on the model, resulting in tractable inference at the expense of expressiveness, and therefore of accuracy and utility, of the model.<br>Motivated by the need to scale inference to large, dense graphical models, in this thesis we explore approximations to Markov chain Monte Carlo (MCMC) and belief propagation (BP) that induce dynamic sparsity in the model to utilize parallelism. In particular, since computations over some factors, variables, and values are more important than over others at different stages of inference, proposed approximations that prioritize and parallelize such computations facilitate efficient inference. First, we show that a synchronously distributed MCMC algorithm that uses dynamic partitioning of the model achieves scalable inference. We then identify bottlenecks in the synchronous architecture, and demonstrate that a collection of MCMC techniques that use asynchronous updates are able to address these drawbacks. For large domains and high-order factors, we find that dynamically inducing sparsity in variable domains, results in scalable belief propagation that enables joint inference. We also show that formulating distributed BP and joint inference as generalized BP on cluster graphs, and by using cluster message approximations, provides significantly lower communication cost and running time.With these tools for inference in hand, we are able to tackle entity tagging, relation extraction, entity resolution, cross-document coreference, joint inference, and other information extraction tasks over large text corpora.",
    "extraLinksSlot" : [ [ "UMass Page", "http://scholarworks.umass.edu/dissertations_2/143/" ] ]
}, {
     "id" : "akbc13",
     "title" : "AKBC 2013: Third Workshop on Automated Knowledge Base Construction",
     "pubTypeSlot" : "Conference",
     "year" : 2013,
     "authorIds" : [ "Fabian M. Suchanek", "sameer", "sebastian", "Partha P. Talukdar" ],
     "venueId" : "cikm",
     "abstractText" : "The AKBC 2013 workshop aims to be a venue of excellence and vision in the area of knowledge base construction. This year's workshop will feature keynotes by ten leading researchers in the field, including from Google, Microsoft, Stanford, and CMU. The submissions focus on visionary ideas instead of on experimental evaluation. Nineteen accepted papers will be presented as posters, with nine exceptional papers also highlighted as spotlight talks. Thereby, the workshop aims provides a vivid forum of discussion about the field of automated knowledge base construction.",
     "pdfLink" : "files/papers/akbc13.pdf",
     "extraLinksSlot" : [ [ "ACM DL", "http://dl.acm.org/citation.cfm?id=2505806" ] ]
}, {
     "id" : "cikm13",
     "title" : "Automated Probabilistic Modeling for Relational Data",
     "pubTypeSlot" : "Conference",
     "year" : 2013,
     "authorIds" : [ "sameer", "thore" ],
     "venueId" : "cikm",
     "abstractText" : "Probabilistic graphical model representations of relational data provide a number of desired features, such as inference of missing values, detection of errors, visualization of data, and probabilistic answers to relational queries. However, adoption has been slow due to the high level of expertise expected both in probability and in the domain from the user. Instead of requiring a domain expert to specify the probabilistic dependencies of the data, we present an approach that uses the relational DB schema to automatically construct a Bayesian graphical model for a database. This resulting model contains customized distributions for the attributes, latent variables that cluster the records, and factors that reflect and represent the foreign key links, whilst allowing efficient inference. Experiments demonstrate the accuracy of the model and scalability of inference on synthetic and real-world data.",
     "pdfLink" : "http://research.microsoft.com/pubs/200220/cikm1335-singh-preprint.pdf",
     "extraLinksSlot" : [ [ "Project Page", "http://research.microsoft.com/apps/pubs/default.aspx?id=200220" ] ]
}, {
  "id" : "kbp13",
  "title" : "Universal Schema for Slot Filling and Cold Start: UMass IESL at TACKBP 2013",
  "pubTypeSlot" : "Conference",
  "year" : 2013,
  "authorIds" : [ "sameer", "limin", "David Belanger", "ari", "Sam Anzaroot", "wick", "Alexandre Passos", "harshal", "jinho", "martin", "andrew" ],
  "venueId" : "tackbp",
  "abstractText" : "We employ universal schema for the TAC KBP slot filling and cold start tasks. The technique enlarges the set of relations in an ontology, e.g., TACKBP slots, to contain all surface patterns between pairs of entities in a large corpus. By factorizing the matrix of co-occurrences between entity pairs and universal schema relations, we are able to predict new target slots. This differs fundamentally from traditional relation extraction approaches because an entire knowledge base is constructed jointly over train and test data. To produce submissions for the slot filling and cold start tasks, we simply query this knowledge base. We describe universal schema, our data preprocessing pipeline, and additional techniques we employ for predicting entities' attributes.",
  "pdfLink" : "files/papers/umass-tackbp13.pdf"
}, {
  "id" : "conll13",
  "title" : "Dynamic Knowledge-Base Alignment for Coreference Resolution",
  "pubTypeSlot" : "Conference",
  "year" : 2013,
  "authorIds" : [ "jiaping", "luke", "sameer", "jinho", "andrew" ],
  "venueId" : "conll",
  "abstractText" : "Coreference resolution systems can benefit greatly from inclusion of global context, and a number of recent approaches have demonstrated improvements when precomputing an alignment to external knowledge sources. However, since alignment itself is a challenging task and is often noisy, existing systems either align conservatively, resulting in very few links, or combine the attributes of multiple candidates, leading to a conflation of entities. Our approach instead performs joint inference between within-document coreference and entity linking, maintaining ranked lists of candidate entities that are dynamically merged and reranked during inference. Further, we incorporate a large set of surface string variations for each entity by using anchor texts from the web that link to the entity. These forms of global context enables our system to improve classifier-based coreference by 1.09 B3 F1 points, and improve over the previous state-of-art by 0.41 points, thus introducing a new state-of-art result on the ACE 2004 data.",
  "pdfLink" : "files/papers/dynamic-conll13.pdf"
}, {
  "id" : "jnt:akbc13",
  "title" : "Joint Inference of Entities, Relations, and Coreference",
  "pubTypeSlot" : "Workshop",
  "year" : 2013,
  "authorIds" : [ "sameer", "sebastian", "martin", "jiaping", "andrew" ],
  "venueId" : "akbc13",
  "pdfLink" : "files/papers/joint-akbc13.pdf"
}, {
  "id" : "conf:akbc13",
  "title" : "Assessing Confidence of Knowledge Base Content with an Experimental Study in Entity Resolution",
  "pubTypeSlot" : "Workshop",
  "year" : 2013,
  "authorIds" : [ "wick", "sameer", "ari", "andrew" ],
  "venueId" : "akbc13",
  "pdfLink" : "files/papers/confidence-akbc13.pdf"
}, {
  "id" : "link:akbc13",
  "title" : "A Joint Model for Discovering and Linking Entities",
  "pubTypeSlot" : "Workshop",
  "year" : 2013,
  "authorIds" : [ "wick", "sameer", "harshal", "andrew" ],
  "venueId" : "akbc13",
  "pdfLink" : "files/papers/linking-akbc13.pdf"
}, {
  "id" : "sparse:reseff13",
  "title" : "Anytime Belief Propagation Using Sparse Domains",
  "pubTypeSlot" : "Workshop",
  "year" : 2013,
  "authorIds" : [ "sameer", "sebastian", "andrew" ],
  "venueId" : "reseff",
  "abstractText" : "Belief Propagation has been widely used for marginal inference, however it is slow on problems with large-domain variables and high-order factors. Previous work provides useful approximations to facilitate inference on such models, but lacks important anytime properties such as: 1) providing accurate and consistent marginals when stopped early, 2) improving the approximation when run longer, and 3) converging to the fixed point of BP. To this end, we propose a message passing algorithm that works on sparse (partially instantiated) domains, and converges to consistent marginals using dynamic message scheduling. The algorithm grows the sparse domains incrementally, selecting the next value to add using prioritization schemes based on the gradients of the marginal inference objective. Our experiments demonstrate local anytime consistency and fast convergence, providing significant speedups over BP to obtain low-error marginals: up to 25 times on grid models, and up to 6 times on a real-world natural language processing task.",
  "pdfLink" : "http://arxiv.org/pdf/1311.3368v1",
  "extraLinksSlot" : [ [ "arXiv Page", "http://arxiv.org/abs/1311.3368" ] ]
}, {
  "id" : "mcmcmc:emnlp12",
  "title" : "Monte Carlo MCMC: Efficient Inference by Approximate Sampling",
  "pubTypeSlot" : "Conference",
  "year" : 2012,
  "authorIds" : [ "sameer", "wick", "andrew" ],
  "venueId" : "emnlp",
  "pdfLink" : "files/papers/mcmcmc-emnlp12.pdf",
  "pptLink" : "files/papers/mcmcmc-emnlp12-ppt.pdf"
}, {
  "id" : "hcoref:acl12",
  "title" : "A Discriminative Hierarchical Model for Fast Coreference at Large Scale",
  "pubTypeSlot" : "Conference",
  "year" : 2012,
  "authorIds" : [ "wick", "sameer", "andrew" ],
  "venueId" : "acl",
  "pdfLink" : "files/papers/hierar-coref-acl12.pdf"
}, {
  "id" : "mldb:probprog12",
  "title" : "Compiling Relational Database Schemata into Probabilistic Graphical Models",
  "pubTypeSlot" : "Workshop",
  "year" : 2012,
  "authorIds" : [ "sameer", "thore" ],
  "venueId" : "probprog",
  "pdfLink" : "http://arxiv.org/pdf/1212.0967v1.pdf",
  "extraLinksSlot" : [ [ "arXiv", "http://arxiv.org/abs/1212.0967" ], [ "Project Page", "http://research.microsoft.com/en-us/projects/inferno/" ]]
}, {
  "id" : "mcmcmc:akbc12",
  "title" : "Monte Carlo MCMC: Efficient Inference by Sampling Factors",
  "pubTypeSlot" : "Workshop",
  "year" : 2012,
  "authorIds" : [ "sameer", "wick", "andrew" ],
  "venueId" : "akbc12",
  "pdfLink" : "files/papers/mcmcmc-akbc12.pdf"
}, {
  "id" : "mcmcge:tr2012",
  "title" : "Constraint-Driven Training of Complex Models Using MCMC",
  "pubTypeSlot" : "TechReport",
  "year" : 2012,
  "authorIds" : [ "sameer", "greg", "andrew" ],
  "venueId" : "University of Massachusetts Amherst, CMPSCI UM-CS-2012-032",
  "pdfLink" : "https://web.cs.umass.edu/publication/docs/2012/UM-CS-2012-032.pdf"
}, {
  "id" : "wlinks:tr2012",
  "title" : "Wikilinks: A Large-scale Cross-Document Coreference Corpus Labeled via Links to Wikipedia",
  "pubTypeSlot" : "TechReport",
  "year" : 2012,
  "authorIds" : [ "sameer", "amar", "fernando", "andrew" ],
  "venueId" : "University of Massachusetts Amherst, CMPSCI UM-CS-2012-015",
  "pdfLink" : "https://web.cs.umass.edu/publication/docs/2012/UM-CS-2012-015.pdf"
}, {
  "id" : "parfs:suml11",
  "title" : "Parallel Large-scale Feature Selection",
  "pubTypeSlot" : "Chapter",
  "year" : 2011,
  "authorIds" : [ "Jeremy Kubica", "sameer", "Daria Sorokina" ],
  "venueId" : "Scaling Up Machine Learning, Cambridge University Press",
  "pdfLink" : "http://additivegroves.net/papers/chapter-featureeval.pdf",
  "extraLinksSlot" : [ [ "Chapter details", "https://www.cambridge.org/core/books/scaling-up-machine-learning/parallel-large-scale-feature-selection/A410E82F4AE61981802CD38C91ABBD68#" ], [ "Book Website", "http://www.cambridge.org/us/knowledge/isbn/item6542017/" ], [ "Amazon", "http://www.amazon.com/Scaling-Machine-Learning-Distributed-Approaches/dp/0521192242" ] ]
}, {
  "id" : "dcoref:acl11",
  "title" : "Large-Scale Cross-Document Coreference Using Distributed Inference and Hierarchical Models",
  "pubTypeSlot" : "Conference",
  "year" : 2011,
  "authorIds" : [ "sameer", "amar", "fernando", "andrew" ],
  "venueId" : "acl",
  "pdfLink" : "files/papers/largescale-acl11.pdf",
  "pptLink" : "files/papers/largescale-acl11-ppt.pdf",
  "emphasisNote" : "Best Talk Award at DARPA Machine Reading Project Kickoff."
}, {
  "id" : "asyncmcmc:biglearn11",
  "title" : "Towards Asynchronous Distributed MCMC Inference for Large Graphical Models",
  "pubTypeSlot" : "Workshop",
  "year" : 2011,
  "authorIds" : [ "sameer", "andrew" ],
  "venueId" : "biglearn",
  "pdfLink" : "files/papers/singh-nipsws11-biglearn.pdf"
}, {
  "id" : "sparsebp:cost11",
  "title" : "Inducing Value Sparsity for Parallel Inference in Tree-shaped Models",
  "pubTypeSlot" : "Workshop",
  "year" : 2011,
  "authorIds" : [ "sameer", "martin", "andrew" ],
  "venueId" : "cost",
  "pdfLink" : "files/papers/singh-nipsws11-cost.pdf",
  "pptLink" : "files/papers/singh-nipsws11-cost-ppt.pdf"
}, {
  "id" : "cons:naacl10",
  "title" : "Constraint-Driven Rank-Based Learning for Information Extraction",
  "pubTypeSlot" : "Conference",
  "year" : 2010,
  "authorIds" : [ "sameer", "limin", "sebastian", "andrew" ],
  "venueId" : "naacl",
  "abstractText" : "Most learning algorithms for factor graphs require complete inference over the dataset or an instance before making an update to the parameters. SampleRank is a rank-based learning framework that alleviates this problem by updating the parameters during inference. Most semi-supervised learning algorithms also rely on the complete inference, i.e. calculating expectations or MAP configurations. We extend the SampleRank framework to the semi-supervised learning, avoiding these inference bottlenecks. Different approaches for incorporating unlabeled data and prior knowledge into this framework are explored. We evaluated our method on a standard information extraction dataset. Our approach outperforms the supervised method significantly and matches the result of the competing semi-supervised learning approach.Most learning algorithms for factor graphs require complete inference over the dataset or an instance before making an update to the parameters. SampleRank is a rank-based learning framework that alleviates this problem by updating the parameters during inference. Most semi-supervised learning algorithms also rely on the complete inference, i.e. calculating expectations or MAP configurations. We extend the SampleRank framework to the semi-supervised learning, avoiding these inference bottlenecks. Different approaches for incorporating unlabeled data and prior knowledge into this framework are explored. We evaluated our method on a standard information extraction dataset. Our approach outperforms the supervised method significantly and matches the result of the competing semi-supervised learning approach.",
  "pdfLink" : "files/papers/constraint-naacl10.pdf",
  "pptLink" : "files/papers/constraint-naacl10-ppt.pdf"
}, {
  "id" : "min:naacl10",
  "title" : "Minimally-Supervised Extraction of Entities from Text Advertisements",
  "pubTypeSlot" : "Conference",
  "year" : 2010,
  "authorIds" : [ "sameer", "Dustin Hillard", "Chris Leggetter" ],
  "venueId" : "naacl",
  "abstractText" : "Extraction of entities from ad creatives is an important problem that can benefit many computational advertising tasks. Supervised and semi-supervised solutions rely on labeled data which is expensive, time consuming, and difficult to procure for ad creatives. A small set of manually derived constraints on feature expectations over unlabeled data can be used to *partially* and *probabilistically* label large amounts of data. Utilizing recent work in constraint-based semi-supervised learning, this paper injects light weight supervision specified as these ``constraints'' into a semi-Markov conditional random field model of entity extraction in ad creatives. Relying solely on the constraints, the model is trained on a set of unlabeled ads using an online learning algorithm. We demonstrate significant accuracy improvements on a manually labeled test set as compared to a baseline dictionary approach. We also achieve accuracy that approaches a fully supervised classifier.",
  "pdfLink" : "files/papers/minimally-naacl10.pdf",
  "pptLink" : "files/papers/minimally-naacl10-ppt.pdf"
}, {
  "id" : "distmap:lccc10",
  "title" : "Distributed MAP Inference for Undirected Graphical Models",
  "pubTypeSlot" : "Workshop",
  "year" : 2010,
  "authorIds" : [ "sameer", "amar", "fernando", "andrew" ],
  "venueId" : "lccc",
  "abstractText" : "In this work, we distribute the MCMC-based MAP inference using the Map-Reduce framework. The variables are assigned randomly to machines, which leads to some factors that neighbor variables on separate machines. Parallel MCMC-chains are initiated using proposal distributions that only suggest local changes such that factors that lie across machines are not examined. After a fixed number of samples on each machine, we redistribute the variables amongst the machines to enable proposals across variables that were on different machines. To demonstrate the distribution strategy on a real-world information extraction application, we model the task of cross-document coreference.",
  "pdfLink" : "files/papers/singh-nipsws10-lccc.pdf",
  "pptLink" : "files/papers/singh-nipsws10-lccc-ppt.pdf",
  "extraLinksSlot" : [ [ "Video", "http://videolectures.net/nipsworkshops2010_singh_dmapi" ] ]
}, {
  "id" : "distantly:tr10",
  "title" : "Distantly Labeling Data for Large Scale Cross-Document Coreference",
  "pubTypeSlot" : "TechReport",
  "year" : 2010,
  "authorIds" : [ "sameer", "wick", "andrew" ],
  "venueId" : "Computing Research Repository (CoRR) eprint arXiv:1005.4298",
  "abstractText" : "Cross-document coreference, the problem of resolving entity mentions across multi-document collections, is crucial to automated knowledge base construction and data mining tasks. However, the scarcity of large labeled data sets has hindered supervised machine learning research for this task. In this paper we develop and demonstrate an approach based on ``distantly-labeling'' a data set from which we can train a discriminative cross-document coreference model. In particular we build a dataset of more than a million people mentions extracted from 3.5 years of New York Times articles, leverage Wikipedia for distant labeling with a generative model (and measure the reliability of such labeling); then we train and evaluate a conditional random field coreference model that has factors on cross-document entities as well as mention-pairs. This coreference model obtains high accuracy in resolving mentions and entities that are not present in the training data, indicating applicability to non-Wikipedia data. Given the large amount of data, our work is also an exercise demonstrating the scalability of our approach.",
  "pdfLink" : "http://arxiv.org/pdf/1005.4298v1",
  "extraLinksSlot" : [ [ "arXiv Page", "http://arxiv.org/abs/1005.4298" ] ]
}, {
  "id" : "rlmap:nips09",
  "title" : "Training Factor Graphs with Reinforcement Learning for Efficient MAP Inference",
  "pubTypeSlot" : "Conference",
  "year" : 2009,
  "authorIds" : [ "wick", "khash", "sameer", "andrew" ],
  "venueId" : "nips",
  "pdfLink" : "files/papers/rl-nips09.pdf"
}, {
  "id" : "factorie:nips09",
  "title" : "FACTORIE: Probabilistic Programming via Imperatively Defined Factor Graphs",
  "pubTypeSlot" : "Conference",
  "year" : 2009,
  "authorIds" : [ "andrew", "karl" , "sameer" ],
  "venueId" : "nips",
  "pdfLink" : "files/papers/factorie-nips09.pdf"
}, {
  "id" : "bidirectional:ecml09",
  "title" : "Bi-directional Joint Inference for Entity Resolution and Segmentation using Imperatively-Defined Factor Graphs",
  "pubTypeSlot" : "Conference",
  "year" : 2009,
  "authorIds" : [ "sameer", "karl", "andrew" ],
  "venueId" : "Machine Learning and Knowledge Discovery in Databases (Lecture Notes in Computer Science) and European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML PKDD)",
  "pdfLink" : "files/papers/bidirectional-ecml09.pdf",
  "pptLink" : "files/papers/bidirectional-ecml09-ppt.pdf",
  "extraLinksSlot" : [ [ "Video", "http://videolectures.net/ecmlpkdd09_singh_bdjiersuidfg" ] ]
}, {
  "id" : "parallel:sdm09",
  "title" : "Parallel Large Scale Feature Selection for Logistic Regression",
  "pubTypeSlot" : "Conference",
  "year" : 2009,
  "authorIds" : [ "sameer", "Jeremy Kubica", "Scott E. Larsen", "Daria Sorokina" ],
  "venueId" : "SIAM International Conference on Data Mining (SDM)",
  "pdfLink" : "files/papers/parallel-sdm09.pdf",
  "pptLink" : "files/papers/parallel-sdm09-ppt.pdf"
}, {
  "id" : "option:synth09",
  "title" : "Option Discovery in Hierarchical Reinforcement Learning for Training Large Factor Graphs for Information Extraction",
  "pubTypeSlot" : "Report",
  "year" : 2009,
  "authorIds" : [ "sameer" ],
  "venueId" : "University of Massachusetts Amherst, PhD Candidacy/Synthesis Report",
  "pdfLink" : "files/papers/optiondiscovery-synthesis09.pdf",
  "note" : "Readers: Andy Barto and Andrew McCallum"
}, {
  "id" : "factorie:nipsws08",
  "title" : "FACTORIE: Efficient Probabilistic Programming via Imperative Declarations of Structure, Inference and Learning",
  "pubTypeSlot" : "Workshop",
  "year" : 2008,
  "authorIds" : [ "andrew", "khash", "wick", "karl", "sameer" ],
  "venueId" : "probprog",
  "pdfLink" : "files/papers/factorie-nipsws08.pdf"
}, {
  "id" : "feature:patent08",
  "title" : "Feature selection for large scale models",
  "pubTypeSlot" : "Patent",
  "year" : 2008,
  "authorIds" : [ "sameer", "E. S. Larsen", "Jeremy Kubica", "Andrew W. Moore" ],
  "venueId" : "US Patent Number 8190537",
  "pdfLink" : "https://docs.google.com/viewer?url=books.google.com/patents/US8190537.pdf",
  "extraLinksSlot" : [ [ "Webpage", "http://www.google.com/patents/US8190537" ] ]
}, {
  "id" : "rlmap:tr08",
  "title" : "Reinforcement Learning for MAP Inference in Large Factor Graphs",
  "pubTypeSlot" : "TechReport",
  "year" : 2008,
  "authorIds" : [ "khash", "wick", "sameer", "andrew" ],
  "venueId" : "University of Massachusetts Amherst, CMPSCI UM-CS-2008-040",
  "pdfLink" : "https://web.cs.umass.edu/publication/docs/2008/UM-CS-2008-040.pdf"
}, {
  "id" : "sqj07",
  "title" : "Common Coupling and Pointer Variables, with Application to a Linux Case Study",
  "pubTypeSlot" : "Journal",
  "year" : 2007,
  "authorIds" : [ "S.R. Schach", "T.O.S. Adeshiyan", "D. Balasubramanian", "G. Madl", "E.P. Osses", "sameer", "K. Suwanmongkol", "M. Xie", "D.G. Feitelson" ],
  "venueId" : "Software Quality Journal (SQJ)",
  "extraFieldsSlot" : [["volume", "15"]],
  "pdfLink" : "files/papers/common-sqj07.pdf"
}, {
  "id" : "jss07",
  "title" : "Fine-Grain Analysis of Common Coupling and its Application to a Linux Case Study",
  "pubTypeSlot" : "Journal",
  "year" : 2007,
  "authorIds" : [ "D.G. Feitelson", "T.O.S. Adeshiyan", "D. Balasubramanian", "Y. Etsion", "G. Madl", "E.P. Osses", "sameer", "K. Suwanmongkol", "M. Xie", "S.R. Schach" ],
  "venueId" : "Journal of Systems and Software (JSS)",
  "extraFieldsSlot" : [["volume", "80"]],
  "pdfLink" : "files/papers/common-jss07.pdf"
}, {
  "id" : "icaps07",
  "title" : "Mixed-Initiative Planning for Space Exploration Missions",
  "pubTypeSlot" : "Workshop",
  "year" : 2007,
  "authorIds" : [ "T. Kichkaylo", "C. van Buskirk", "sameer", "H. Neema", "M. Orosz", "R. Neches" ],
  "venueId" : "International Conference on Automated Planning and Scheduling Workshop (ICAPS)"
}, {
  "id" : "icra06",
  "title" : "Transfer of Learning for Complex Domains: A Demonstration Using Multiple Robots",
  "pubTypeSlot" : "Conference",
  "year" : 2006,
  "authorIds" : [ "sameer", "Julie A. Adams" ],
  "venueId" : "International Conference on Robotics and Automation (ICRA)",
  "pdfLink" : "files/papers/transfer-icra06.pdf"
}, {
  "id" : "incarf03",
  "title" : "Finding the shortest path for a mobile robot in an unmapped maze from minimum runs",
  "pubTypeSlot" : "Conference",
  "year" : 2003,
  "authorIds" : [ "sameer" ],
  "venueId" : "Int Conf on CAD, CAM, Robotics and Autonomous Factories (INCARF)"
} ]
